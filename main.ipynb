{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d68f15-bdd9-464c-b83b-60c69a15a66c",
   "metadata": {},
   "source": [
    "## 🧰 Step 1. 导入依赖与路径设置\n",
    "本节导入所需依赖包，并配置基础路径。\n",
    "- 若第一次运行，需要确保：\n",
    "  - `lib/` 目录下包含 `glove.840B.300d.txt`\n",
    "  - `corpus/imdb/` 目录下包含 Kaggle 提供的 `.tsv` 文件\n",
    "## 💾 Step 2. 加载或生成 GloVe 向量（.kv 格式）\n",
    "此步骤会检测 `lib/` 目录下的文件：\n",
    "1. 若已有 `glove.840B.300d.kv`，则直接加载；\n",
    "2. 若只有 `.gensim.txt` 或 `.txt` 文件，会自动转换生成 `.kv`。\n",
    "`.kv` 格式的优势：\n",
    "- 加载更快（几秒）\n",
    "- 占内存更少（mmap 方式）\n",
    "- 避免 `EOFError` 及文件损坏风险\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "099c7bf7-73fe-45a8-91a8-bee9ea9535ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 13:15:35,603: INFO: 开始检测并加载 GloVe 文件...\n",
      "2025-10-19 13:15:35,608: INFO: 检测到 .gensim.txt 文件，尝试加载: lib/glove.840B.300d.gensim.txt\n",
      "2025-10-19 13:15:35,609: INFO: loading projection weights from lib/glove.840B.300d.gensim.txt\n",
      "2025-10-19 13:20:30,023: WARNING: 加载 .gensim.txt 失败: unexpected end of input; is count incorrect or file otherwise damaged?\n",
      "2025-10-19 13:20:30,260: WARNING: 尝试从原始 glove.840B.300d.txt 加载（no_header=True）...\n",
      "2025-10-19 13:20:30,262: INFO: loading projection weights from lib/glove.840B.300d.txt\n",
      "2025-10-19 13:21:04,936: WARNING: duplicate word '����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������' in word2vec file, ignoring all but first\n",
      "2025-10-19 13:25:28,961: INFO: KeyedVectors lifecycle event {'msg': 'loaded (2196017, 300) matrix of type float32 from lib/glove.840B.300d.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-10-19T13:25:28.960865', 'gensim': '4.3.3', 'python': '3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:20:11) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'load_word2vec_format'}\n",
      "2025-10-19 13:25:28,963: INFO: 加载成功！保存为 .kv 缓存中...\n",
      "2025-10-19 13:25:28,967: INFO: KeyedVectors lifecycle event {'fname_or_handle': 'lib/glove.840B.300d.kv', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-10-19T13:25:28.967395', 'gensim': '4.3.3', 'python': '3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:20:11) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'saving'}\n",
      "2025-10-19 13:25:28,977: INFO: storing np array 'vectors' to lib/glove.840B.300d.kv.vectors.npy\n",
      "2025-10-19 13:25:33,015: INFO: saved lib/glove.840B.300d.kv\n",
      "2025-10-19 13:25:33,017: INFO: 保存完成：lib/glove.840B.300d.kv\n",
      "2025-10-19 13:25:33,017: INFO: ✅ 加载完成：词汇量 = 2196016，维度 = 300\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "glove_convert.py\n",
    "用途：将 glove.840B.300d.txt 转换为高效的 gensim / kv 格式\n",
    "支持自动检测文件、异常修复、日志输出\n",
    "\"\"\"\n",
    "import os\n",
    "import logging\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# ========== 日志配置 ==========\n",
    "logging.basicConfig(format=\"%(asctime)s: %(levelname)s: %(message)s\",\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ========== 文件路径 ==========\n",
    "glove_txt = \"lib/glove.840B.300d.txt\"          # 原始官方文件（2GB）\n",
    "gensim_txt = \"lib/glove.840B.300d.gensim.txt\"  # 转换后的文本\n",
    "kv_bin = \"lib/glove.840B.300d.kv\"              # 高效二进制缓存\n",
    "\n",
    "# ========== 开始加载 ==========\n",
    "logger.info(\"开始检测并加载 GloVe 文件...\")\n",
    "\n",
    "wvmodel = None\n",
    "\n",
    "# 1️⃣ 优先加载二进制 .kv（最快）\n",
    "if os.path.exists(kv_bin):\n",
    "    logger.info(\"检测到 .kv 文件，直接加载（mmap='r'）: %s\", kv_bin)\n",
    "    wvmodel = KeyedVectors.load(kv_bin, mmap='r')\n",
    "\n",
    "# 2️⃣ 若无 .kv，尝试加载 .gensim.txt\n",
    "elif os.path.exists(gensim_txt):\n",
    "    try:\n",
    "        logger.info(\"检测到 .gensim.txt 文件，尝试加载: %s\", gensim_txt)\n",
    "        wvmodel = KeyedVectors.load_word2vec_format(gensim_txt, binary=False)\n",
    "        logger.info(\"加载成功，保存为 .kv 以便下次快速读取...\")\n",
    "        wvmodel.save(kv_bin)\n",
    "        logger.info(\"已保存至: %s\", kv_bin)\n",
    "    except Exception as e:\n",
    "        logger.warning(\"加载 .gensim.txt 失败: %s\", e)\n",
    "\n",
    "# 3️⃣ 若以上都没有或损坏，则直接从 .txt 读取（no_header=True）\n",
    "if wvmodel is None:\n",
    "    if not os.path.exists(glove_txt):\n",
    "        raise FileNotFoundError(\"未找到原始 GloVe 文件，请确认路径正确。\")\n",
    "    logger.warning(\"尝试从原始 glove.840B.300d.txt 加载（no_header=True）...\")\n",
    "    wvmodel = KeyedVectors.load_word2vec_format(glove_txt, binary=False, no_header=True)\n",
    "    logger.info(\"加载成功！保存为 .kv 缓存中...\")\n",
    "    wvmodel.save(kv_bin)\n",
    "    logger.info(\"保存完成：%s\", kv_bin)\n",
    "\n",
    "# ========== 验证加载结果 ==========\n",
    "logger.info(\"✅ 加载完成：词汇量 = %d，维度 = %d\",\n",
    "            len(wvmodel.key_to_index), wvmodel.vector_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6185b332-5a28-4ffa-9948-2af42e5cee3c",
   "metadata": {},
   "source": [
    "## 🎬 Step 3. 构建 IMDB 数据集\n",
    "此步骤执行以下流程：\n",
    "1. 加载 IMDB 训练 / 测试 `.tsv` 文件  \n",
    "2. 使用 `BeautifulSoup` 清洗文本  \n",
    "3. 构建词汇表  \n",
    "4. 编码为索引序列并填充至固定长度  \n",
    "5. 使用 GloVe 向量构建 embedding 矩阵  \n",
    "6. 序列化输出到 `pickle/imdb_glove.pickle3`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaff8dec-4db7-46dd-8a03-77f0f752fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 13:43:08,923: INFO: running D:\\Anaconda\\Lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\22711\\AppData\\Roaming\\jupyter\\runtime\\kernel-a488ede4-750d-4260-805b-7db9d5cf9eb4.json\n",
      "2025-10-19 13:43:09,673: INFO: train shape: (25000, 3) | test shape: (25000, 2)\n",
      "2025-10-19 13:43:09,674: INFO: cleaning & tokenizing train/test reviews ...\n",
      "C:\\Users\\22711\\AppData\\Local\\Temp\\ipykernel_17584\\567924533.py:42: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  review_text = BeautifulSoup(str(review), \"html.parser\").get_text()\n",
      "2025-10-19 13:43:24,728: INFO: building vocabulary ...\n",
      "2025-10-19 13:43:25,303: INFO: vocab size: 101399\n",
      "2025-10-19 13:43:25,303: INFO: train/val split ...\n",
      "2025-10-19 13:43:25,342: INFO: loading GloVe model from lib\\glove.840B.300d.kv\n",
      "2025-10-19 13:43:25,343: INFO: loading KeyedVectors object from lib\\glove.840B.300d.kv\n",
      "2025-10-19 13:43:26,273: INFO: loading vectors from lib\\glove.840B.300d.kv.vectors.npy with mmap=r\n",
      "2025-10-19 13:43:26,288: INFO: KeyedVectors lifecycle event {'fname': 'lib\\\\glove.840B.300d.kv', 'datetime': '2025-10-19T13:43:26.288106', 'gensim': '4.3.3', 'python': '3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:20:11) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26200-SP0', 'event': 'loaded'}\n",
      "2025-10-19 13:43:26,289: INFO: GloVe loaded: vocab=2196016, dim=300\n",
      "2025-10-19 13:43:26,289: INFO: building word_to_idx / idx_to_word ...\n",
      "2025-10-19 13:43:26,354: INFO: encoding & padding ...\n",
      "2025-10-19 13:43:31,703: INFO: building embedding weight matrix ...\n",
      "C:\\Users\\22711\\AppData\\Local\\Temp\\ipykernel_17584\\567924533.py:149: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  weight[idx, :] = torch.from_numpy(wvmodel.get_vector(word))\n",
      "2025-10-19 13:43:43,663: INFO: initialized embeddings for 77553 / 101399 words (76.48% covered)\n",
      "2025-10-19 13:43:43,664: INFO: saving dataset to pickle/imdb_glove.pickle3 ...\n",
      "2025-10-19 13:43:44,216: INFO: ✅ Done! Saved preprocessed data to pickle/imdb_glove.pickle3\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "imdb_glove.py\n",
    "功能：将 IMDB 影评数据集转换为基于 GloVe 预训练词向量的索引化张量数据\n",
    "输出：pickle/imdb_glove.pickle3\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ========= 基本参数 =========\n",
    "embed_size = 300         # GloVe 维度\n",
    "max_len = 512            # 每条样本的最大长度\n",
    "imdb_dir = \"./corpus/imdb\"\n",
    "pickle_out = \"pickle/imdb_glove.pickle3\"\n",
    "\n",
    "# ========= 数据路径 =========\n",
    "train_path = os.path.join(imdb_dir, \"labeledTrainData.tsv\")\n",
    "test_path = os.path.join(imdb_dir, \"testData.tsv\")\n",
    "unlabeled_path = os.path.join(imdb_dir, \"unlabeledTrainData.tsv\")  # 可选文件\n",
    "\n",
    "# ========= GloVe 路径 =========\n",
    "kv_file = os.path.join(\"lib\", \"glove.840B.300d.kv\")  # 已生成的高效文件\n",
    "\n",
    "\n",
    "# ========== 文本清洗函数 ==========\n",
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    文本清洗：去 HTML 标签、去非字母字符、小写化并分词\n",
    "    \"\"\"\n",
    "    review_text = BeautifulSoup(str(review), \"html.parser\").get_text()\n",
    "    review_text = re.sub(r\"[^a-zA-Z]\", \" \", review_text)\n",
    "    words = review_text.lower().split()\n",
    "    return words\n",
    "\n",
    "\n",
    "# ========== 编码函数 ==========\n",
    "def encode_samples(tokenized_samples, word_to_idx):\n",
    "    \"\"\"\n",
    "    将词转换为索引序列（未知词为 0）\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for sample in tokenized_samples:\n",
    "        feature = [word_to_idx.get(token, 0) for token in sample]\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "\n",
    "# ========== Padding 函数 ==========\n",
    "def pad_samples(features, maxlen=max_len, PAD=0):\n",
    "    \"\"\"\n",
    "    截断或填充样本到固定长度\n",
    "    \"\"\"\n",
    "    padded = []\n",
    "    for seq in features:\n",
    "        if len(seq) >= maxlen:\n",
    "            padded.append(seq[:maxlen])\n",
    "        else:\n",
    "            padded.append(seq + [PAD] * (maxlen - len(seq)))\n",
    "    return padded\n",
    "\n",
    "\n",
    "# ========== 主程序 ==========\n",
    "def main():\n",
    "    # ========== 日志配置 ==========\n",
    "    program = os.path.basename(sys.argv[0])\n",
    "    logger = logging.getLogger(program)\n",
    "    logging.basicConfig(format=\"%(asctime)s: %(levelname)s: %(message)s\")\n",
    "    logging.root.setLevel(level=logging.INFO)\n",
    "    logger.info(\"running %s\", \" \".join(sys.argv))\n",
    "\n",
    "    # ========== 路径检查 ==========\n",
    "    for p in [train_path, test_path]:\n",
    "        if not os.path.exists(p):\n",
    "            raise FileNotFoundError(f\"未找到数据文件：{p}，请确认 IMDB TSV 已放在 {imdb_dir}\")\n",
    "\n",
    "    if not os.path.exists(kv_file):\n",
    "        raise FileNotFoundError(f\"未找到 {kv_file}，请先运行 glove_convert.py 生成 .kv 文件\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(pickle_out), exist_ok=True)\n",
    "\n",
    "    # ========== 读取 IMDB 数据 ==========\n",
    "    train = pd.read_csv(train_path, header=0, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    test = pd.read_csv(test_path, header=0, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    logger.info(\"train shape: %s | test shape: %s\", train.shape, test.shape)\n",
    "\n",
    "    # ========== 文本清洗 ==========\n",
    "    logger.info(\"cleaning & tokenizing train/test reviews ...\")\n",
    "    clean_train_reviews, train_labels = [], []\n",
    "    for i, review in enumerate(train[\"review\"]):\n",
    "        clean_train_reviews.append(review_to_wordlist(review))\n",
    "        train_labels.append(int(train[\"sentiment\"][i]))\n",
    "    clean_test_reviews = [review_to_wordlist(r) for r in test[\"review\"]]\n",
    "\n",
    "    # ========== 构建词表 ==========\n",
    "    logger.info(\"building vocabulary ...\")\n",
    "    vocab = set(chain(*clean_train_reviews)) | set(chain(*clean_test_reviews))\n",
    "    vocab_size = len(vocab)\n",
    "    logger.info(\"vocab size: %d\", vocab_size)\n",
    "\n",
    "    # ========== 划分验证集 ==========\n",
    "    logger.info(\"train/val split ...\")\n",
    "    train_reviews, val_reviews, train_labels_arr, val_labels_arr = train_test_split(\n",
    "        clean_train_reviews, train_labels, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    # ========== 加载 GloVe ==========\n",
    "    logger.info(\"loading GloVe model from %s\", kv_file)\n",
    "    wvmodel = KeyedVectors.load(kv_file, mmap='r')\n",
    "    logger.info(\"GloVe loaded: vocab=%d, dim=%d\",\n",
    "                len(wvmodel.key_to_index), wvmodel.vector_size)\n",
    "\n",
    "    # ========== 构建词 ↔ 索引 ==========\n",
    "    logger.info(\"building word_to_idx / idx_to_word ...\")\n",
    "    word_to_idx = {word: i + 1 for i, word in enumerate(vocab)}\n",
    "    word_to_idx[\"<unk>\"] = 0\n",
    "    idx_to_word = {i + 1: word for i, word in enumerate(vocab)}\n",
    "    idx_to_word[0] = \"<unk>\"\n",
    "\n",
    "    # ========== 编码 & padding ==========\n",
    "    logger.info(\"encoding & padding ...\")\n",
    "    train_features = torch.tensor(pad_samples(encode_samples(train_reviews, word_to_idx)))\n",
    "    val_features = torch.tensor(pad_samples(encode_samples(val_reviews, word_to_idx)))\n",
    "    test_features = torch.tensor(pad_samples(encode_samples(clean_test_reviews, word_to_idx)))\n",
    "\n",
    "    train_labels_t = torch.tensor(train_labels_arr, dtype=torch.long)\n",
    "    val_labels_t = torch.tensor(val_labels_arr, dtype=torch.long)\n",
    "\n",
    "    # ========== 构建 embedding 权重矩阵 ==========\n",
    "    logger.info(\"building embedding weight matrix ...\")\n",
    "    weight = torch.zeros(vocab_size + 1, embed_size, dtype=torch.float32)\n",
    "\n",
    "    exist = 0\n",
    "    for word, idx in word_to_idx.items():\n",
    "        if word == \"<unk>\":\n",
    "            continue\n",
    "        if word in wvmodel.key_to_index:\n",
    "            weight[idx, :] = torch.from_numpy(wvmodel.get_vector(word))\n",
    "            exist += 1\n",
    "    logger.info(\"initialized embeddings for %d / %d words (%.2f%% covered)\",\n",
    "                exist, vocab_size, 100 * exist / vocab_size)\n",
    "\n",
    "    # ========== 保存 ==========\n",
    "    logger.info(\"saving dataset to %s ...\", pickle_out)\n",
    "    with open(pickle_out, \"wb\") as f:\n",
    "        pickle.dump(\n",
    "            [\n",
    "                train_features,\n",
    "                train_labels_t,\n",
    "                val_features,\n",
    "                val_labels_t,\n",
    "                test_features,\n",
    "                weight,\n",
    "                word_to_idx,\n",
    "                idx_to_word,\n",
    "                vocab,\n",
    "            ],\n",
    "            f,\n",
    "        )\n",
    "    logger.info(\"✅ Done! Saved preprocessed data to %s\", pickle_out)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e90d04-8d93-4fd9-a63b-2d5bb8263979",
   "metadata": {},
   "source": [
    "## 🔍 Step 4. 验证数据文件\n",
    "加载并查看结构是否正确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5029607-74d5-4f9e-aa5d-4cbd79ae4b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据文件加载成功！\n",
      "\n",
      "训练集特征: torch.Size([20000, 512]), 标签: torch.Size([20000])\n",
      "验证集特征: torch.Size([5000, 512]), 标签: torch.Size([5000])\n",
      "测试集特征: torch.Size([25000, 512])\n",
      "Embedding 矩阵: torch.Size([101400, 300])\n",
      "词汇表大小: 101399\n",
      "示例词向量（'good'）:\n",
      "tensor([-0.4263,  0.4431, -0.3452, -0.1326, -0.0582,  0.0526,  0.2157, -0.3672,\n",
      "        -0.0452,  2.2444])\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "check_imdb_pickle.py\n",
    "快速检查 imdb_glove.pickle3 是否正确生成\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "path = \"pickle/imdb_glove.pickle3\"\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train_features, train_labels, val_features, val_labels, test_features, weight, word_to_idx, idx_to_word, vocab = data\n",
    "\n",
    "print(\"✅ 数据文件加载成功！\\n\")\n",
    "print(f\"训练集特征: {train_features.shape}, 标签: {train_labels.shape}\")\n",
    "print(f\"验证集特征: {val_features.shape}, 标签: {val_labels.shape}\")\n",
    "print(f\"测试集特征: {test_features.shape}\")\n",
    "print(f\"Embedding 矩阵: {weight.shape}\")\n",
    "print(f\"词汇表大小: {len(vocab)}\")\n",
    "print(f\"示例词向量（'good'）:\")\n",
    "print(weight[word_to_idx.get('good', 0)][:10])  # 打印前10个维度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85352fc1-d626-4bce-8583-925aad26d64b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
